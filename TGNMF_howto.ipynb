{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisite\n",
    "This notebook requires the following package to execute fully :\n",
    "\n",
    "* beta-ntf (https://code.google.com/archive/p/beta-ntf/)\n",
    "* groupNMF (https://github.com/rserizel/groupNMF)\n",
    "        \n",
    "Note: group-NMF is not required if you just load the pre-computed dictionnaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rserizel/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder, scale\n",
    "\n",
    "from beta_ntf import BetaNTF\n",
    "from tnmf import SupervisedDL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading the scikit learn toy digits dataset and\n",
    "creating one train-test split of equal size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature learning with unsupervised NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Before introducing the supervised model lets start by presenting the unsupervised equivalent: an NMF followed by a logistic regression.\n",
    "We fit a nonnegative matrix factorizationon the training images and keep the projections for classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting NTF model with 100 iterations....\n",
      "Done.\n",
      "Fitting NTF model with 100 iterations....\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "nmf = BetaNTF(data_shape=X_train.shape, n_components=10, \n",
    "                                   n_iter=100, verbose=False, beta=2)\n",
    "nmf.fit(X_train)\n",
    "W_uns = nmf.factors_[1]\n",
    "H_train = nmf.factors_[0]\n",
    "\n",
    "\n",
    "nmf = BetaNTF(data_shape=X_test.shape, n_components=10, \n",
    "                                   n_iter=100, verbose=False, beta=2)\n",
    "nmf.fixed_factors = [1]\n",
    "nmf.factors_[1]  = W_uns\n",
    "nmf.fit(X_test)\n",
    "H_test = nmf.factors_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy score for NMF with logisitc regression : 0.91 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.98      0.97        94\n",
      "          1       0.88      0.80      0.83        88\n",
      "          2       0.95      0.97      0.96        93\n",
      "          3       0.86      0.85      0.86        80\n",
      "          4       0.93      0.97      0.95       101\n",
      "          5       0.96      0.94      0.95        97\n",
      "          6       0.97      0.97      0.97        93\n",
      "          7       0.96      0.98      0.97        90\n",
      "          8       0.83      0.81      0.82        78\n",
      "          9       0.81      0.85      0.83        85\n",
      "\n",
      "avg / total       0.91      0.91      0.91       899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = LogisticRegression(C=10,  multi_class='multinomial', solver='lbfgs')\n",
    "clf.fit(H_train,y_train)\n",
    "y_pred = clf.predict(H_test)\n",
    "\n",
    "print(\" Accuracy score for NMF with logisitc regression : %0.2f \\n\"%accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised feature learning with TD-NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying the supverised model we need to make sure the labels are integers in between 0 and (n_labels-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lb  = LabelEncoder()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the digits toy problem, we use the model in its most basic formulation: without group similarity constraints.\n",
    "Once the model is initialized, it is used similarly to scikit-learn classifier with the fit and predict functions. \n",
    "\n",
    "The most important parameters to tune are: \n",
    "\n",
    "_ \"n_components\" -> the size of the dictionary.\n",
    "\n",
    "_ \"mu\" -> to constrain the weights of the classifier and prevent overfitting (equivalent of the \"C\" parameter in scikit-learn models). \n",
    "\n",
    "_ \"rho\" -> to control the initial gradient step. Should be modified if the cost increases or decreases to slowly.\n",
    "  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rserizel/anaconda2/lib/python2.7/site-packages/spams.py:424: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  if D == None:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy score for NMF with logisitc regression : 0.94 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.96        94\n",
      "          1       0.89      0.97      0.93        88\n",
      "          2       0.99      0.86      0.92        93\n",
      "          3       0.92      1.00      0.96        80\n",
      "          4       0.98      0.98      0.98       101\n",
      "          5       0.99      0.93      0.96        97\n",
      "          6       0.97      0.98      0.97        93\n",
      "          7       1.00      0.99      0.99        90\n",
      "          8       0.84      0.87      0.86        78\n",
      "          9       0.89      0.89      0.89        85\n",
      "\n",
      "avg / total       0.95      0.94      0.94       899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tdnmf = SupervisedDL(data=X_train, n_components=10, n_labels=10, pos=True, n_iter=10,\n",
    "                     batch_size=1, agreg=1,rho =0.001)\n",
    "\n",
    "tdnmf.fit(X_train, y_train, X_test, y_test)\n",
    "y_pred = tdnmf.predict(X_test)\n",
    "W_sup = tdnmf.D\n",
    "\n",
    "\n",
    "print(\" Accuracy score for NMF with logisitc regression : %0.2f \\n\"%accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducing TG-NMF \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAE+CAYAAACzyQiOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3e2f3e1750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "L = len(X)/4\n",
    "X = X[:4*L,:]\n",
    "y = y[:4*L] \n",
    "sessions = np.zeros(y.shape)\n",
    "\n",
    "for i in range(4):\n",
    "    X[i*L:(i+1)*L,i*16:(i+1)*16] += (3+2*np.abs(np.random.randn(L,16)))\n",
    "    sessions[i*L:(i+1)*L] += i\n",
    "X_train, X_test, y_train, y_test, sessions_train, sessions_test = train_test_split(X, y, sessions, test_size=.5, random_state=123)\n",
    "\n",
    "fig, ax = plt.subplots(3, 5, subplot_kw=dict(xticks=[], yticks=[]))\n",
    "for j in range(5):\n",
    "    for i in range(3):\n",
    "        im = ax[i, j].imshow(X_train[i*3 +j,:].reshape((8, 8)),\n",
    "                             cmap=plt.cm.binary, interpolation='nearest') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain dictionnary with GNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group NMF with class specific rules for beta-divergence\n",
      "Compute contraint distances at each segment update\n",
      "Reordering data...\n",
      "Fitting NMF model with 100 iterations....\n",
      "Total duration=2573.0ms\n"
     ]
    }
   ],
   "source": [
    "from beta_nmf_class import ClassBetaNMF\n",
    "nmf = ClassBetaNMF(\n",
    "    X_train, y_train, sessions_train, n_components=(1, 1, 1), beta=2, NMF_updates='groupNMF',\n",
    "    n_iter=100, normalize=True, verbose=0)\n",
    "nmf.fit(X_train, y_train, sessions_train)\n",
    "D = nmf.select([0, 1])\n",
    "lbl = nmf.iters['cls'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternatively load pre-computed dictionnaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ajouter un wget ici pour aller chercher les données\n",
    "D = np.load('gnmf_dic.npy')\n",
    "lbl = np.load('gnmf_lbl.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting NTF model with 100 iterations....\n",
      "Done.\n",
      "Fitting NTF model with 100 iterations....\n",
      "Done.\n",
      " Accuracy score for NMF with logisitc regression : 0.84 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.89      0.93        94\n",
      "          1       0.76      0.74      0.75        90\n",
      "          2       0.82      0.87      0.84        89\n",
      "          3       0.85      0.80      0.82        85\n",
      "          4       0.91      0.87      0.89       104\n",
      "          5       0.90      0.89      0.89        97\n",
      "          6       0.89      0.94      0.91        84\n",
      "          7       0.84      0.88      0.86        94\n",
      "          8       0.66      0.68      0.67        74\n",
      "          9       0.77      0.80      0.79        87\n",
      "\n",
      "avg / total       0.84      0.84      0.84       898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ntf = BetaNTF(data_shape=X_train.shape, n_components=10, \n",
    "                                   n_iter=100, verbose=False, beta=2)\n",
    "ntf.fit(X_train)\n",
    "W_uns = ntf.factors_[1]\n",
    "H_train = ntf.factors_[0]\n",
    "\n",
    "\n",
    "ntf = BetaNTF(data_shape=X_test.shape, n_components=10, \n",
    "                                   n_iter=100, verbose=False, beta=2)\n",
    "ntf.fixed_factors = [1]\n",
    "ntf.factors_[1]  = W_uns\n",
    "ntf.fit(X_test)\n",
    "H_test = ntf.factors_[0]\n",
    "\n",
    "clf = LogisticRegression(C=10,  multi_class='multinomial', solver='lbfgs')\n",
    "clf.fit(H_train,y_train)\n",
    "y_pred = clf.predict(H_test)\n",
    "\n",
    "print(\" Accuracy score for NMF with logisitc regression : %0.2f \\n\"%accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy score for NMF with logisitc regression : 0.95 \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        94\n",
      "          1       0.94      0.97      0.95        90\n",
      "          2       0.96      0.98      0.97        89\n",
      "          3       0.95      0.89      0.92        85\n",
      "          4       0.99      0.99      0.99       104\n",
      "          5       0.97      0.95      0.96        97\n",
      "          6       0.97      0.99      0.98        84\n",
      "          7       0.96      0.98      0.97        94\n",
      "          8       0.94      0.82      0.88        74\n",
      "          9       0.86      0.94      0.90        87\n",
      "\n",
      "avg / total       0.95      0.95      0.95       898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tgnmf import SupervisedDL\n",
    "tdnmf = SupervisedDL(data=X_train, n_labels=10, pos=True, n_iter=2,\n",
    "                     batch_size=1, agreg=1,rho =0.00001, lbl=lbl,\n",
    "                     max_iter_init=5, max_iter_fin=5,\n",
    "                     ses_train=sessions, sub_dict_size=2,  k_cls=1, \n",
    "                     k_ses=1,  nu1=0.00001, nu2=0.000001)\n",
    "tdnmf.D = D\n",
    "tdnmf.fit(X_train, y_train, X_test, y_test)\n",
    "y_pred = tdnmf.predict(X_test)\n",
    "W_sup = tdnmf.D\n",
    "\n",
    "\n",
    "print(\" Accuracy score for NMF with logisitc regression : %0.2f \\n\"%accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
