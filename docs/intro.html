<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Supervised group NMF &#8212; TNMF 1.0 documentation</title>
    
    <link rel="stylesheet" href="_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    './',
        VERSION:     '1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Documentation" href="doc.html" />
    <link rel="prev" title="Supervised group-NMF" href="index.html" /> 
  </head>
  <body role="document">
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="doc.html" title="Documentation"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="index.html" title="Supervised group-NMF"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">TNMF 1.0 documentation</a> &#187;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="supervised-group-nmf">
<h1>Supervised group NMF<a class="headerlink" href="#supervised-group-nmf" title="Permalink to this headline">¶</a></h1>
<p>In <a class="footnote-reference" href="#id16" id="id1">[1]</a>, we adapted a supervised matrix factorization model known as <em>Task-driven Dictionary Learning</em> (TDL) <a class="footnote-reference" href="#id18" id="id2">[3]</a>} to suit the ASC task. We introduced a variant of the TDL model in its nonnegative formulation <a class="footnote-reference" href="#id19" id="id3">[4]</a>, including a modification of the original algorithm, where a nonnegative dictionary is jointly learned with a multi-class classifier. In <a class="footnote-reference" href="#id17" id="id4">[2]</a> we proposed a new formulation of the Group nonnegative matrix factorisation (<a class="reference external" href="http://rserizel.github.io/groupNMF/intro.html">GNMF</a>) method. Using the Euclidean distance as the divergence for the <a class="reference external" href="http://rserizel.github.io/groupNMF/intro.html">GNMF</a> problem, the dictionary learning based on <a class="reference external" href="http://rserizel.github.io/groupNMF/intro.html">GNMF</a> is integrated in a supervised framework inspired by TDL <a class="footnote-reference" href="#id18" id="id5">[3]</a>.</p>
<div class="section" id="gnmf-with-speaker-and-session-similarity">
<h2>GNMF with speaker and session similarity<a class="headerlink" href="#gnmf-with-speaker-and-session-similarity" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="http://rserizel.github.io/groupNMF/intro.html">Details</a> and <a class="reference external" href="https://github.com/rserizel/groupNMF">source code</a> for the GNMF <a class="footnote-reference" href="#id18" id="id6">[3]</a> .</p>
</div>
<div class="section" id="task-driven-nmf-based-dictionary-learning">
<h2>Task-driven NMF based dictionary learning<a class="headerlink" href="#task-driven-nmf-based-dictionary-learning" title="Permalink to this headline">¶</a></h2>
<p>TDL <a class="footnote-reference" href="#id19" id="id7">[4]</a> has recently been applied with nonnegativity constraints to perform speech enhancement[5]_ or to acoustic scene classification, where temporally integrated projections are classified with multinomial logistic regression <a class="footnote-reference" href="#id16" id="id8">[1]</a>. In <a class="footnote-reference" href="#id17" id="id9">[2]</a> we extended the latter approach to the <a class="reference external" href="http://rserizel.github.io/groupNMF/intro.html">GNMF</a> case.</p>
<div class="section" id="task-driven-nmf">
<h3>Task-driven NMF<a class="headerlink" href="#task-driven-nmf" title="Permalink to this headline">¶</a></h3>
<p>The general idea of nonnegative TDL or task-driven NMF (TNMF) is to unite the dictionary learning with NMF and the training of the classifier in a joint optimization problem <a class="footnote-reference" href="#id16" id="id10">[1]</a>, <a class="footnote-reference" href="#id20" id="id11">[5]</a>. Influenced by the classifier, the basis vectors are encouraged to explain the discriminative information in the data while keeping a low reconstruction cost. The TNMF model first considers the optimal projections <span class="math">\(\textbf{h}^{\star}(\textbf{v},\textbf{W})\)</span> of the data points <span class="math">\(\textbf{v}\)</span> on the dictionary textbf{W}, which are defined as solutions of the nonnegative elastic-net problem <a class="footnote-reference" href="#id21" id="id12">[6]</a>, expressed as:</p>
<div class="math" id="equation-elastic">
<span class="eqno">(1)<a class="headerlink" href="#equation-elastic" title="Permalink to this equation">¶</a></span>\[\textbf{h}^{\star}(\textbf{v},\textbf{W}) = \min_{\textbf{h} \in \mathbb{R}_+^{K}}\ \frac{1}{2}\|\textbf{v}-\textbf{W}\textbf{h}\|_{2}^{2}+\lambda_{1}\|\textbf{h}\|_{1}+\frac{\lambda_{2}}{2}\|\textbf{h}\|_{2}^{2};\]</div>
<p>where <span class="math">\(\lambda_{1}\)</span> and <span class="math">\(\lambda_{2}\)</span> are nonnegative regularization parameters. Given each data segment <span class="math">\(\textbf{V}^{(l)}\)</span> of length <span class="math">\(M\)</span> frames, associated with a label <span class="math">\(y\)</span> in a fixed set of labels <span class="math">\(\mathcal{Y}\)</span>, we want to classify the mean of the projections of the data points <span class="math">\(\textbf{v}^{(l)}\)</span> belonging to the segment <span class="math">\(l\)</span>, such that <span class="math">\(\textbf{V}^{(l)}=[\textbf{v}_{0}^{(l)},...,\textbf{v}_{M-1}^{(l)}]\)</span>. We define <span class="math">\(\hat{\textbf{h}}^{(l)}\)</span> as the averaged projection of <span class="math">\(\textbf{V}^{(l)}\)</span> on the dictionary, where <span class="math">\(\hat{\textbf{h}}^{(l)}=\frac{1}{M}\sum_{m=0}^{M-1}\textbf{h}^{\star}(\textbf{v}_{m}^{(l)},\textbf{W})\)</span>. The corresponding classification loss (here using multinomial logistic regression) is defined as <span class="math">\(l_{s}(y,\textbf{A},\hat{\textbf{h}}^{(l)})\)</span>, where <span class="math">\(\textbf{A}\in \mathcal{A}\)</span> are the parameters of the classifier. The TNMF problem is then expressed as a joint minimization of the expected classification loss over <span class="math">\(\textbf{W}\)</span> and <span class="math">\(\textbf{A}\)</span>:</p>
<div class="math">
\[\min_{\textbf{W} \in \mathcal{W}, \textbf{A} \in \mathcal{A}} f(\textbf{W},\textbf{A})+\frac{\nu}{2}\|\textbf{A}\|_{2}^{2},\]</div>
<p>with</p>
<div class="math" id="equation-TDL">
<span class="eqno">(2)<a class="headerlink" href="#equation-TDL" title="Permalink to this equation">¶</a></span>\[f(\textbf{W},\textbf{A}) = \mathbb{E}_{y,\textbf{V}^{(l)}}\ [l_{s}(y,\textbf{A},\hat{\textbf{h}}^{(l)}(\textbf{v}^{(l)},\textbf{W}))].\]</div>
<p>Here, <span class="math">\(\mathcal{W}\)</span> is defined as the set of nonnegative dictionaries containing unit <span class="math">\(l_{2}\)</span>-norm basis vectors and <span class="math">\(\nu\)</span> is a regularization parameter on the classifier parameters, meant to prevent over-fitting. The problem in equation <a class="reference internal" href="#equation-TDL">(2)</a> is optimized with mini-batch stochastic gradient descent as described in the paper of Bisot <em>et al.</em> <a class="footnote-reference" href="#id16" id="id13">[1]</a>.</p>
</div>
<div class="section" id="task-driven-gnmf">
<h3>Task-driven GNMF<a class="headerlink" href="#task-driven-gnmf" title="Permalink to this headline">¶</a></h3>
<p>In task-driven <a class="reference external" href="http://rserizel.github.io/groupNMF/intro.html">GNMF</a> (TGNMF) we propose to perform jointly the dictionary learning based on <a class="reference external" href="http://rserizel.github.io/groupNMF/intro.html">GNMF</a> <a class="footnote-reference" href="#id17" id="id14">[2]</a> and the training of a multinomial logistic regression. The dictionary <span class="math">\(\textbf{W}\)</span> is then the concatenation of all the sub-dictionaries <span class="math">\(\textbf{W}^{(cs)}\)</span> and the optimal projections <span class="math">\(\textbf{h}^{\star}(\textbf{v},\textbf{W})\)</span> are the solutions of <a class="reference internal" href="#equation-elastic">(1)</a>.</p>
<p>Including the <a class="reference external" href="http://rserizel.github.io/groupNMF/intro.html#class-and-session-similarity-constraints">similarity constraints</a> , the TGNMF is thus expressed as the minimization of the following problem:</p>
<div class="math">
\[\min_{\textbf{W}\in \mathcal{W}, \textbf{A} \in \mathcal{A}} f(\textbf{W},\textbf{A})+\frac{\mu}{2}\|\textbf{A}\|_{2}^{2} + \nu_1 J_{\mathrm{SPK}} + \nu_2 J_{\mathrm{SES}},\]</div>
<p>with <span class="math">\(f(\textbf{W},\textbf{A})\)</span> as defined above. The problem is again optimized with mini-batch stochastic gradient descent. However, as opposed to the previous algorithm, for each data point <span class="math">\(\textbf{v}\)</span> belonging to a particular <span class="math">\(\textbf{V}^{(cs)}\)</span>, only the corresponding sub-dictionaries (<span class="math">\(\textbf{W}^{(cs)}\)</span>) are updated, whereas the other dictionaries are left unchanged in order to match the <a class="reference external" href="http://rserizel.github.io/groupNMF/intro.html">GNMF</a> adaptation scheme <a class="footnote-reference" href="#id17" id="id15">[2]</a>.</p>
</div>
</div>
<div class="section" id="download">
<h2>Download<a class="headerlink" href="#download" title="Permalink to this headline">¶</a></h2>
<p>Source code available at <a class="reference external" href="https://github.com/rserizel/TGNMF">https://github.com/rserizel/TGNMF</a></p>
</div>
<div class="section" id="getting-started">
<h2>Getting Started<a class="headerlink" href="#getting-started" title="Permalink to this headline">¶</a></h2>
<p>A short example is available as at <a class="reference external" href="https://github.com/rserizel/TGNMF/blob/master/TGNMF_howto.ipynb">https://github.com/rserizel/TGNMF/blob/master/TGNMF_howto.ipynb</a></p>
</div>
<div class="section" id="citation">
<h2>Citation<a class="headerlink" href="#citation" title="Permalink to this headline">¶</a></h2>
<p>If you are using this source code please consider citing one of the following papers:</p>
<div class="topic">
<p class="topic-title first">References</p>
<table class="docutils footnote" frame="void" id="id16" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[1]</td><td><ol class="first last upperalpha simple" start="22">
<li>Bisot, R. Serizel, S. Essid, and G. Richard. &#8220;Feature Learning with Matrix Factorization Applied to Acoustic Scene Classification&#8221;. Accepted for publication in <em>IEEE Transactions on Audio, Speech and Language Processing</em>, 2017</li>
</ol>
</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id17" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[2]</td><td><ol class="first last upperalpha simple" start="18">
<li>Serizel, V.Bisot, S. Essid, and G. Richard. &#8220;Supervised group nonnegative matrix factorisation with similarity constraints and applications to speaker identification&#8221;. In Proc. of <em>2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 2017.</li>
</ol>
</td></tr>
</tbody>
</table>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="nd">@article</span><span class="p">{</span><span class="n">bisot2017TASLP</span><span class="p">,</span>
<span class="n">title</span><span class="o">=</span><span class="p">{</span><span class="n">Feature</span> <span class="n">Learning</span> <span class="k">with</span> <span class="n">Matrix</span> <span class="n">Factorization</span> <span class="n">Applied</span> <span class="n">to</span> <span class="n">Acoustic</span> <span class="n">Scene</span> <span class="n">Classification</span><span class="p">},</span>
<span class="n">author</span><span class="o">=</span><span class="p">{</span><span class="n">Serizel</span><span class="p">,</span> <span class="n">Romain</span> <span class="ow">and</span> <span class="n">Bisot</span><span class="p">,</span> <span class="n">Victor</span> <span class="ow">and</span> <span class="n">Essid</span><span class="p">,</span> <span class="n">Slim</span> <span class="ow">and</span> <span class="n">Richard</span><span class="p">,</span> <span class="n">Ga</span><span class="p">{</span>\<span class="s2">&quot;e}l},</span>
<span class="n">journal</span><span class="o">=</span><span class="p">{</span><span class="n">IEEE</span> <span class="n">Transactions</span> <span class="n">on</span> <span class="n">Audio</span><span class="p">,</span> <span class="n">Speech</span> <span class="ow">and</span> <span class="n">Language</span> <span class="n">Processing</span><span class="p">},</span>
<span class="n">pages</span><span class="o">=</span><span class="p">{</span><span class="mi">14</span><span class="p">},</span>
<span class="n">year</span><span class="o">=</span><span class="p">{</span><span class="mi">2017</span><span class="p">},</span>
<span class="n">organization</span><span class="o">=</span><span class="p">{</span><span class="n">IEEE</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="nd">@inproceedings</span><span class="p">{</span><span class="n">serizel2017ICASSP</span><span class="p">,</span>
<span class="n">title</span><span class="o">=</span><span class="p">{</span><span class="n">Supervised</span> <span class="n">group</span> <span class="n">nonnegative</span> <span class="n">matrix</span> <span class="n">factorisation</span> <span class="k">with</span> <span class="n">similarity</span> <span class="n">constraints</span> <span class="ow">and</span> <span class="n">applications</span> <span class="n">to</span> <span class="n">speaker</span> <span class="n">identification</span><span class="p">},</span>
<span class="n">author</span><span class="o">=</span><span class="p">{</span><span class="n">Serizel</span><span class="p">,</span> <span class="n">Romain</span> <span class="ow">and</span> <span class="n">Bisot</span><span class="p">,</span> <span class="n">Victor</span> <span class="ow">and</span> <span class="n">Essid</span><span class="p">,</span> <span class="n">Slim</span> <span class="ow">and</span> <span class="n">Richard</span><span class="p">,</span> <span class="n">Ga</span><span class="p">{</span>\<span class="s2">&quot;e}l},</span>
<span class="n">booktitle</span><span class="o">=</span><span class="p">{</span><span class="n">IEEE</span> <span class="n">International</span> <span class="n">Conference</span> <span class="n">on</span> <span class="n">Acoustics</span><span class="p">,</span> <span class="n">Speech</span> <span class="ow">and</span> <span class="n">Signal</span> <span class="n">Processing</span> <span class="p">(</span><span class="n">ICASSP</span><span class="p">)},</span>
<span class="n">pages</span><span class="o">=</span><span class="p">{</span><span class="mi">5</span><span class="p">},</span>
<span class="n">year</span><span class="o">=</span><span class="p">{</span><span class="mi">2017</span><span class="p">},</span>
<span class="n">organization</span><span class="o">=</span><span class="p">{</span><span class="n">IEEE</span><span class="p">}</span>
<span class="p">}</span><span class="n">Download</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<table class="docutils footnote" frame="void" id="id18" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[3]</td><td><ol class="first last upperalpha simple" start="18">
<li>Serizel, S. Essid, and G. Richard. “Group nonnegative matrix factorisation with speaker and session variability compensation for speaker identification”. In Proc. of <em>2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, pp. 5470-5474, 2016.</li>
</ol>
</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id19" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[4]</td><td><ol class="first last upperalpha simple" start="10">
<li>Mairal, F. Bach and J. Ponce. &#8220;Task-driven dictionary learning&#8221;. In <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, vol 34(4), pp. 791&#8211;804, 2012.</li>
</ol>
</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id20" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[5]</td><td><ol class="first last upperalpha simple" start="16">
<li>Sprechmann, A. M. Bronstein and G. Sapiro. &#8220;Supervised non-euclidean sparse NMF via bilevel optimization with applications to speech enhancement&#8221;. In Proc. <em>Joint Workshop on Hands-free Speech Communication and Microphone Arrays (HSCMA)</em>, pp. 11-15, 2014.</li>
</ol>
</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id21" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[6]</td><td><ol class="first last upperalpha simple" start="8">
<li>Zou and T. Hastie. &#8220;Regularization and variable selection via the elastic net&#8221;. In <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, vol 67(2), pp. 301&#8211;320, 2015.</li>
</ol>
</td></tr>
</tbody>
</table>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Supervised group NMF</a><ul>
<li><a class="reference internal" href="#gnmf-with-speaker-and-session-similarity">GNMF with speaker and session similarity</a></li>
<li><a class="reference internal" href="#task-driven-nmf-based-dictionary-learning">Task-driven NMF based dictionary learning</a><ul>
<li><a class="reference internal" href="#task-driven-nmf">Task-driven NMF</a></li>
<li><a class="reference internal" href="#task-driven-gnmf">Task-driven GNMF</a></li>
</ul>
</li>
<li><a class="reference internal" href="#download">Download</a></li>
<li><a class="reference internal" href="#getting-started">Getting Started</a></li>
<li><a class="reference internal" href="#citation">Citation</a></li>
<li><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="index.html"
                        title="previous chapter">Supervised group-NMF</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="doc.html"
                        title="next chapter">Documentation</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/intro.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="doc.html" title="Documentation"
             >next</a> |</li>
        <li class="right" >
          <a href="index.html" title="Supervised group-NMF"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">TNMF 1.0 documentation</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2017, Victor Bisot, Romain Serizel.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.5.1.
    </div>
  </body>
</html>